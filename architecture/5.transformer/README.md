# Transformer

## ğŸ§¾ Tá»•ng quan
**Transformer** khÃ´ng chá»‰ cÃ³ kháº£ nÄƒng mÃ´ hÃ¬nh hÃ³a sÃ¢u (deep modeling) vÃ  kháº£ nÄƒng má»Ÿ rá»™ng (scalability), mÃ  cÃ²n thá»ƒ hiá»‡n **kháº£ nÄƒng thÃ­ch á»©ng máº¡nh máº½ vá»›i nhiá»u modality khÃ¡c nhau**.

Trong cÃ¡c nhiá»‡m vá»¥ Ä‘a phÆ°Æ¡ng thá»©c, cháº³ng háº¡n nhÆ° **Text-based Person Re-ID**, Transformer Ä‘Ã£ trá»Ÿ thÃ nh **ná»n táº£ng cÃ´ng nghá»‡ quan trá»ng**, nhá» vÃ o kháº£ nÄƒng **trÃ­ch xuáº¥t vÃ  cÄƒn chá»‰nh hiá»‡u quáº£ cÃ¡c Ä‘áº·c trÆ°ng vÄƒn báº£n vÃ  hÃ¬nh áº£nh**. [77, 82, 119, 120, 78, 8, 99, 84, 118, 98, 90, 79, 2, 85, 34, 114, 121, 37, 122, 35, 38, 39, 40, 41, 42, 43, 44, 123]

Theo **cÃ¡ch mÃ´ hÃ¬nh xá»­ lÃ½ vÄƒn báº£n vÃ  hÃ¬nh áº£nh**, cÃ¡c framework cÃ´ng nghá»‡ hiá»‡n nay cÃ³ thá»ƒ chia thÃ nh **hai loáº¡i chÃ­nh**:
- Dual-stream Encoding
- Unified Large Models Era Encoding

## Dual-stream Encoding
Dual-stream Encoding sá»­ dá»¥ng cÃ¡c **bá»™ mÃ£ hÃ³a Ä‘á»™c láº­p cho vÄƒn báº£n vÃ  hÃ¬nh áº£nh** Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« cáº£ hai modality.
- Má»—i bá»™ mÃ£ hÃ³a (vÃ­ dá»¥: BERT, Swin Transformer) táº­p trung vÃ o kiá»ƒu dá»¯ liá»‡u riÃªng cá»§a nÃ³:
    - VÄƒn báº£n: sá»­ dá»¥ng Transformer [94] vÃ  BERT [8, 99, 84, 118, 98, 90, 79, 2, 85, 34, 114, 121, 122, 45] Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ngá»¯ cáº£nh.
    - HÃ¬nh áº£nh: sá»­ dá»¥ng Vision Transformer [124, 121], Swin Transformer [78, 37, 45], Pyramid ViT [85]... Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng Ä‘a tá»‰ lá»‡ tá»« áº£nh ngÆ°á»i.

Sau Ä‘Ã³, Ä‘áº·c trÆ°ng cá»§a cáº£ hai modality Ä‘Æ°á»£c **chiáº¿u vÃ o cÃ¹ng má»™t khÃ´ng gian** Ä‘á»ƒ so khá»›p thÃ´ng qua má»™t cÆ¡ cháº¿ cÄƒn chá»‰nh Ä‘áº·c thÃ¹ (vÃ­ dá»¥: Contrastive Learning).

### Má»™t sá»‘ cÃ´ng trÃ¬nh tiÃªu biá»ƒu
- **Li et al.** [119]: Ä‘á» xuáº¥t máº¡ng **SAF (Semantically-Aligned Feature aggregation)** dá»±a trÃªn Vision Transformer, cÃ³ kháº£ nÄƒng gom cÃ¡c Ä‘áº·c trÆ°ng cÃ³ cÃ¹ng ngá»¯ nghÄ©a thÃ nh nhá»¯ng Ä‘áº·c trÆ°ng cá»¥c bá»™ riÃªng biá»‡t.
- **Ji et al.** [78]: Ä‘Æ°a ra phÆ°Æ¡ng phÃ¡p **Asymmetric Cross-Scale Alignment (ACSA)** dÃ¹ng Swin Transformer Ä‘á»ƒ cÄƒn chá»‰nh toÃ n cá»¥c giá»¯a hÃ¬nh áº£nh vÃ  vÄƒn báº£n, sau Ä‘Ã³ cÄƒn chá»‰nh Ä‘á»™ng cÃ¡c thá»±c thá»ƒ cross-modal, giáº£i quyáº¿t váº¥n Ä‘á» lá»‡ch tá»‰ lá»‡ (scale alignment).
- **Shao et al.** [118]: Ä‘á» xuáº¥t **LGUR (Learning Granularity-Unified Representations)** dá»±a trÃªn DeiT-Transformer, Ã¡nh xáº¡ Ä‘áº·c trÆ°ng hÃ¬nh áº£nh vÃ  vÄƒn báº£n vÃ o má»™t khÃ´ng gian thá»‘ng nháº¥t vá» má»©c Ä‘á»™ chi tiáº¿t (granularity).
- **Ref.** [85]: xÃ¢y dá»±ng khung tokenization vÃ  cÄƒn chá»‰nh Ä‘áº·c trÆ°ng dá»±a trÃªn Pyramid ViT, giÃºp dáº§n thu háº¹p khoáº£ng cÃ¡ch giá»¯a cÃ¡c modality vÃ  giá»¯a cÃ¡c lá»›p (inter/intra-class).
- **Li et al.** [121]: phÃ¡t triá»ƒn mÃ´ hÃ¬nh **MSN-BRR (Multi-Granularity Separation Network with Bidirectional Refinement Regularization)**, chá»‰ dÃ¹ng BERT Ä‘á»ƒ mÃ£ hÃ³a vÄƒn báº£n, táº­p trung xá»­ lÃ½ nhiá»…u liÃªn-modal.
- **Yang et al.** [37]: Ä‘á» xuáº¥t **APTM (Attribute Prompt Learning and Text Matching Learning)** dá»±a trÃªn Swin Transformer, bá»• sung explicit attribute recognition Ä‘á»ƒ cáº£i thiá»‡n representation learning.
- **Ref.** [122]: khai thÃ¡c thÃ´ng tin bá»‹ bá» sÃ³t báº±ng phÆ°Æ¡ng phÃ¡p dá»±a trÃªn Vision Transformer, káº¿t há»£p khai thÃ¡c Ä‘áº·c trÆ°ng tiáº¿n trÃ¬nh vÃ  tri thá»©c ngoÃ i Ä‘á»ƒ tinh lá»c Ä‘áº·c trÆ°ng.
- **Li et al.** [45]: giáº£i quyáº¿t váº¥n Ä‘á» khoáº£ng cÃ¡ch liÃªn-modal vÃ  biáº¿n thiÃªn ná»™i/ngoáº¡i lá»›p báº±ng khung **AUL (Adaptive Uncertainty Based Learning)** dá»±a trÃªn Swin Transformer.
- **Shu et al.** [94]: Ä‘á» xuáº¥t khung **IVT (Implicit Visual Text)**, trong Ä‘Ã³ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÄƒn báº£n vÃ  hÃ¬nh áº£nh dÃ¹ng chung má»™t backbone Transformer (chia sáº» tham sá»‘). CÃ¡ch nÃ y, tá»‘i Æ°u báº±ng dá»¯ liá»‡u cross-modal, cho phÃ©p mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c má»™t Ã¡nh xáº¡ khÃ´ng gian chung.

## Unified Large Models Era Encoding
Vá»›i sá»± phÃ¡t triá»ƒn máº¡nh máº½ cá»§a cÃ¡c **mÃ´ hÃ¬nh Ä‘a phÆ°Æ¡ng thá»©c quy mÃ´ lá»›n Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n (pre-trained multimodal models)**, cÃ¡c Unified Large Models (mÃ´ hÃ¬nh thá»‘ng nháº¥t) mang Ä‘áº¿n má»™t **khung Transformer chung** giÃºp **káº¿t há»£p sÃ¢u giá»¯a cÃ¡c Ä‘áº·c trÆ°ng Ä‘a phÆ°Æ¡ng thá»©c** (áº£nh vÃ  vÄƒn báº£n) thÃ´ng qua **chia sáº» tham sá»‘ hoáº·c tiá»n huáº¥n luyá»‡n chung**.
Nhá»¯ng mÃ´ hÃ¬nh nÃ y thá»ƒ hiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a (generalization) vÃ  hiá»‡u suáº¥t vÆ°á»£t trá»™i trong nhiá»u tÃ¡c vá»¥ thá»‹ giÃ¡c-ngÃ´n ngá»¯ [35, 38].

Cá»¥ thá»ƒ, **Ä‘áº¡i diá»‡n chung giá»¯a cÃ¡c mÃ´ thá»©c (cross-modal representation)** Ä‘Æ°á»£c há»c thÃ´ng qua **tiá»n huáº¥n luyá»‡n trÃªn bá»™ dá»¯ liá»‡u áº£nh-vÄƒn báº£n cá»±c lá»›n** (vÃ­ dá»¥ nhÆ° **400 triá»‡u cáº·p áº£nhâ€“chÃº thÃ­ch trong CLIP [126]**).
Nhá» quÃ¡ trÃ¬nh huáº¥n luyá»‡n nÃ y, **cÃ¡c Ä‘áº·c trÆ°ng chi tiáº¿t (fine-grained features)** mÃ  Text-based Person Re-ID cáº§n Ä‘Ã£ Ä‘Æ°á»£c há»c sáºµn, nÃªn cÃ¡c mÃ´ hÃ¬nh Unified Large Models chá»‰ cáº§n **fine-tune nháº¹** Ä‘á»ƒ thÃ­ch á»©ng vá»›i cÃ¡c tÃ¡c vá»¥ downstream nhÆ° tÃ¬m ngÆ°á»i qua mÃ´ táº£ [39â€“44].

### Má»™t sá»‘ cÃ´ng trÃ¬nh tiÃªu biá»ƒu:
- **Yan et al.** [38] Ä‘á» xuáº¥t **CFine**, khung khai thÃ¡c thÃ´ng tin chi tiáº¿t (fine-grained) Ä‘Æ°á»£c dáº«n dáº¯t bá»Ÿi bá»™ mÃ£ hÃ³a hÃ¬nh áº£nh cá»§a CLIP, táº­n dá»¥ng tri thá»©c cÃ³ sáºµn tá»« CLIP Ä‘á»ƒ khai thÃ¡c thÃ´ng tin má»©c chi tiáº¿t phá»¥c vá»¥ TIReID (Text-Image Re-ID).
- **Ref.** [39] chá»‰ ra ráº±ng chá»‰ sá»­ dá»¥ng bá»™ mÃ£ hÃ³a hÃ¬nh áº£nh (visual encoder) mÃ  bá» qua bá»™ mÃ£ hÃ³a vÄƒn báº£n (text encoder) sáº½ lÃ m máº¥t Ä‘i kháº£ nÄƒng cÄƒn chá»‰nh giá»¯a cÃ¡c mÃ´ thá»©c (modal alignment) mÃ  CLIP Ä‘Ã£ há»c Ä‘Æ°á»£c trong quÃ¡ trÃ¬nh tiá»n huáº¥n luyá»‡n.
VÃ¬ váº­y, cÃ¡c mÃ´ hÃ¬nh TPS (Text-based Person Search) sau Ä‘Ã³ Ä‘Ã£ táº­n dá»¥ng cáº£ hai bá»™ mÃ£ hÃ³a cá»§a CLIP Ä‘á»ƒ khai thÃ¡c tá»‘i Ä‘a thÃ´ng tin song phÆ°Æ¡ng.
- **IRRA** [40] giáº£i quyáº¿t váº¥n Ä‘á» biáº¿n dáº¡ng thÃ´ng tin ná»™i mÃ´ thá»©c (intra-modal distortion) báº±ng cÃ¡ch suy luáº­n quan há»‡ áº©n (implicit relational inference) vÃ  cÄƒn chá»‰nh Ä‘áº·c trÆ°ng mÃ  khÃ´ng cáº§n há»c giÃ¡m sÃ¡t trÆ°á»›c giá»¯a cÃ¡c vÃ¹ng hÃ¬nh áº£nh vÃ  tá»« mÃ´ táº£.
- **Zuo et al.** [44] â€“ CFAM (CLIP-based Fine-grained Alignment Model)
Äá» xuáº¥t má»™t kiáº¿n trÃºc CLIP-based cho truy há»“i vÄƒn báº£n siÃªu chi tiáº¿t (ultra-fine-grained retrieval).
MÃ´ hÃ¬nh nÃ y dÃ¹ng decoder chia sáº» má»©c háº¡t (granularity decoder) vÃ  cÆ¡ cháº¿ hard-negative matching Ä‘á»ƒ tinh chá»‰nh cÄƒn chá»‰nh Ä‘a phÆ°Æ¡ng thá»©c.

### HÆ°á»›ng kháº¯c phá»¥c váº¥n Ä‘á» thá»±c táº¿:
Äá»‘i máº·t vá»›i cÃ¡c váº¥n Ä‘á» nhÆ° **thiáº¿u dá»¯ liá»‡u (incomplete data)**, **nhiá»…u dá»¯ liá»‡u (data noise)** vÃ  **quyá»n riÃªng tÆ° (privacy)** trong mÃ´i trÆ°á»ng thá»±c táº¿ má»Ÿ, cÃ¡c nghiÃªn cá»©u sau Ä‘Ã£ má»Ÿ rá»™ng kháº£ nÄƒng thÃ­ch á»©ng cá»§a CLIP:
- **Du et al. [41] â€“ iTIReID (Incomplete Textual Image Re-ID)** sá»­ dá»¥ng **Ä‘áº·c trÆ°ng phÃ¢n cá»¥m (clustering features)** Ä‘á»ƒ **bÃ¹ Ä‘áº¯p cÃ¡c mÃ´ thá»©c bá»‹ thiáº¿u**, cho phÃ©p mÃ´ hÃ¬nh há»c hiá»‡u quáº£ ngay cáº£ vá»›i dá»¯ liá»‡u khÃ´ng Ä‘áº§y Ä‘á»§.
- **Gong et al. [42] â€“ RTIReID (Robust Text-Image Re-ID)** má»Ÿ rá»™ng khoáº£ng cÃ¡ch giá»¯a cÃ¡c lá»›p (inter-class distance) Ä‘á»ƒ giáº£m phÆ°Æ¡ng sai trong lá»›p (intra-class variance), Ä‘á»“ng thá»i Ã¡p dá»¥ng **nearest-neighbor consistent complementation** nháº±m khÃ´i phá»¥c Ä‘áº·c trÆ°ng bá»• sung cháº¥t lÆ°á»£ng cao.
- **Qin et al. [43] â€“ RDE (Robust Double Embedding)** Ä‘á» xuáº¥t phÆ°Æ¡ng phÃ¡p há»c **liÃªn káº¿t ngá»¯ nghÄ©a thá»‹ giÃ¡c máº¡nh máº½**, trÃ¡nh mÃ´ hÃ¬nh bá»‹ sá»¥p Ä‘á»• (collapse) khi dá»¯ liá»‡u bá»‹ nhiá»…u, Ä‘á»“ng thá»i táº­p trung vÃ o **cÃ¡c máº«u hard-negative** Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t.

Cáº£ ba mÃ´ hÃ¬nh nÃ y Ä‘á»u sá»­ dá»¥ng **CLIP-ViT** vÃ  **CLIP-Transformer (Xformer)** lÃ m bá»™ mÃ£ hÃ³a áº£nh vÃ  vÄƒn báº£n.