# Äá»‹nh hÆ°á»›ng Ä‘á» tÃ i luáº­n vÄƒn

**"Empirical Zero/Few-Shot Text-based Person Search with Prompt-Guided Visual Enhancement"**

## 1. LÃ½ do chá»n Ä‘á» tÃ i & Ä‘iá»ƒm cáº§n cáº£i thiá»‡n
- **(Gap 1) Háº¡n cháº¿ trong kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a (open-set / zero-shot):**
    - CÃ¡c mÃ´ hÃ¬nh Text-based Person Search (TBPS) hiá»‡n nay nhÆ° VFE-TPS, RaSa, hay TBPS-CLIP chá»§ yáº¿u hoáº¡t Ä‘á»™ng trong closed-set setting, tá»©c lÃ  chá»‰ cÃ³ thá»ƒ nháº­n dáº¡ng nhá»¯ng ID Ä‘Ã£ xuáº¥t hiá»‡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
    - Trong thá»±c táº¿, ngÆ°á»i dÃ¹ng thÆ°á»ng mÃ´ táº£ nhá»¯ng ngÆ°á»i chÆ°a tá»«ng tháº¥y trÆ°á»›c Ä‘Ã³. Do Ä‘Ã³, cáº§n hÆ°á»›ng nghiÃªn cá»©u zero-shot vÃ  few-shot adaptation Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh á»©ng dá»¥ng.
- **(Gap 2) ChÆ°a táº­n dá»¥ng tá»‘t ngá»¯ nghÄ©a sÃ¢u tá»« ngÃ´n ngá»¯ tá»± nhiÃªn:**
    - CÃ¡c há»‡ thá»‘ng hiá»‡n táº¡i chá»§ yáº¿u sá»­ dá»¥ng text encoder cá»‘ Ä‘á»‹nh (nhÆ° BERT hoáº·c CLIP encoder) mÃ  chÆ°a khai thÃ¡c sá»©c máº¡nh cá»§a LLM-based prompt expansion, semantic paraphrasing hay context enrichment, vá»‘n giÃºp mÃ´ hÃ¬nh hiá»ƒu sÃ¢u hÆ¡n mÃ´ táº£ cá»§a ngÆ°á»i dÃ¹ng.
- **(Gap 3) Thiáº¿u Ä‘a dáº¡ng dá»¯ liá»‡u mÃ´ táº£ vÃ  hÃ¬nh áº£nh:**
    - CÃ¡c táº­p dá»¯ liá»‡u nhÆ° CUHK-PEDES vÃ  RSTPReid cÃ³ sá»‘ lÆ°á»£ng mÃ´ táº£ ngáº¯n, Ã­t biáº¿n thá»ƒ; hÃ¬nh áº£nh háº¡n cháº¿, khÃ´ng Ä‘á»§ Ä‘áº¡i diá»‡n cho cÃ¡c ID chÆ°a tháº¥y.
    - Do Ä‘Ã³, cáº§n bá»• sung text & image augmentation â€” bao gá»“m paraphrase, synonym substitution, LLM-driven captioning, hoáº·c diffusion-based image synthesis.
- **(Gap 4) Chi phÃ­ huáº¥n luyá»‡n vÃ  suy luáº­n cao:**
    - CÃ¡c mÃ´ hÃ¬nh nhÆ° RaSa sá»­ dá»¥ng pipeline phá»©c táº¡p gá»“m segmentation / region alignment hoáº·c multi-stage training, gÃ¢y tá»‘n thá»i gian vÃ  tÃ i nguyÃªn.
    - Cáº§n má»™t thiáº¿t káº¿ nháº¹ hÆ¡n, inference nhanh, Æ°u tiÃªn global feature alignment nhÆ° trong VFE-TPS nhÆ°ng váº«n giá»¯ Ä‘á»™ chÃ­nh xÃ¡c cao.
- **(Gap 5) Thiáº¿u module alignment linh hoáº¡t & hiá»‡u quáº£:**
    - Nhiá»u nghiÃªn cá»©u váº«n freeze backbone CLIP hoáº·c fine-tune toÃ n bá»™ model, chÆ°a khai thÃ¡c cÃ¡c cÆ¡ cháº¿ prompt tuning, cross-modal adapter, giÃºp cÃ¢n báº±ng giá»¯a chi phÃ­ tÃ­nh toÃ¡n vÃ  kháº£ nÄƒng thÃ­ch á»©ng ngá»¯ nghÄ©a.

## 2. Má»¥c tiÃªu luáº­n vÄƒn
- PhÃ¡t triá»ƒn mÃ´ hÃ¬nh **zero-shot / few-shot text-based person search** â€” cÃ³ thá»ƒ truy váº¥n nhá»¯ng ID chÆ°a tá»«ng gáº·p trong training.
- TÄƒng cÆ°á»ng dá»¯ liá»‡u mÃ´ táº£ / Ä‘áº·c trÆ°ng báº±ng cÃ¡ch **augmentation mÃ´ táº£ vÄƒn báº£n** (paraphrase, synonym substitution, LLM prompt expansion) vÃ /hoáº·c **sinh áº£nh giáº£ tá»« mÃ´ táº£** (diffusion model) Ä‘á»ƒ há»— trá»£ alignment.
- Thiáº¿t káº¿ module alignment hiá»‡u quáº£ (cross-modal attention, contrastive alignment, prompt tuning) Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a.
- Tá»‘i Æ°u chi phÃ­ inference vÃ  training so vá»›i baseline nhÆ° RaSa, thÃ´ng qua thiáº¿t káº¿ kiáº¿n trÃºc gá»n nháº¹ dá»±a trÃªn global feature alignment vÃ  empirical efficiency analysis.
- ÄÃ¡nh giÃ¡ trÃªn cÃ¡c dataset chuáº©n vÃ  thiáº¿t láº­p thá»­ nghiá»‡m open-set (loáº¡i bá» má»™t sá»‘ ID trong training, dÃ¹ng cho test).

## 3. PhÆ°Æ¡ng phÃ¡p Ä‘á» xuáº¥t (káº¿ hoáº¡ch / pipeline thá»±c nghiá»‡m)
- **(Step 1) Backbone káº¿t há»£p:**
    - DÃ¹ng CLIP-ViT-B/16 lÃ m ná»n táº£ng chÃ­nh.
    - Káº¿t há»£p cÆ¡ cháº¿ alignment cá»§a TBPS-CLIP (R-ITC / Cyclic) [arXiv](https://arxiv.org/html/2308.10045v2) vá»›i visual enhancement tá»« VFE-TPS (TG-MIM + IS-GVFC).
- **(Step 2) Zero-shot / few-shot training setup:**
    - Chia ID thÃ nh seen/unseen splits.
    - Ãp dá»¥ng prompt tuning vÃ  meta-learning episodic training Ä‘á»ƒ mÃ´ hÃ¬nh thÃ­ch nghi nhanh vá»›i ID má»›i.
- **(Step 3) Text augmentation:**
    - Sá»­ dá»¥ng LLM (vÃ­ dá»¥ GPT-4/5) Ä‘á»ƒ sinh paraphrase, synonym substitution, attribute expansion.
    - Triá»ƒn khai prompt-based augmentation pipeline tá»± Ä‘á»™ng hÃ³a sinh mÃ´ táº£ má»›i cho má»—i áº£nh.
- **(Step 4) Image synthesis augmentation:**
    - DÃ¹ng text-to-image diffusion model (Stable Diffusion, SDXL) Ä‘á»ƒ sinh thÃªm áº£nh pedestrian theo mÃ´ táº£ text (style-constrained generation).
    - DÃ¹ng áº£nh tá»•ng há»£p nÃ y trong pre-training Ä‘á»ƒ cáº£i thiá»‡n alignment.
- **(Step 5) Alignment module hiá»‡u quáº£:**
    - ThÃªm Cross-Modal Attention (CMA) + Prompt Tuning Layer giá»¯a encoder text vÃ  image.
    - Huáº¥n luyá»‡n vá»›i loss káº¿t há»£p: ğ¿ = ğ¿_ğ‘…âˆ’ğ¼ğ‘‡ğ¶ + ğ¿_ğ‘‡ğºâˆ’ğ‘€ğ¼ğ‘€ + ğ¿_ğ¼ğ‘†âˆ’ğºğ‘‰ğ¹ğ¶ + ğœ†_1 * ğ¿_ğ‘ƒğ‘Ÿğ‘œğ‘šğ‘ğ‘¡ğ‘…ğ‘’ğ‘”
    - Chá»‰ fine-tune prompt vÃ  adapter â†’ giáº£m chi phÃ­ training.
- **(Step 6) Evaluation:**
    - Benchmark trÃªn CUHK-PEDES, ICFG-PEDES vá»›i zero-shot split.
    - So sÃ¡nh vá»›i RaSa, TBPS-CLIP, VFE-TPS vá»: Rank@1, mAP, inference time.

## 4. ÄÃ³ng gÃ³p ká»³ vá»ng
- Giáº£i quyáº¿t háº¡n cháº¿ closed-set assumption trong text-based person search.
- ÄÆ°a ra phÆ°Æ¡ng phÃ¡p augmentation mÃ´ táº£ + attention alignment Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng generalization.
- CÃ³ thá»ƒ cÃ³ á»©ng dá»¥ng trong thá»±c táº¿: truy váº¥n ngÆ°á»i má»›i chÆ°a trong dá»¯ liá»‡u huáº¥n luyá»‡n.

## 5. TÃ i liá»‡u khá»Ÿi Ä‘iá»ƒm / Ä‘á»c thÃªm (nÃªn Ä‘á»c)
- Dong et al., Person Search by Text Attribute Query as Zero-Shot Learning (ICCV 2019). [Xiatian Zhu](https://xiatian-zhu.github.io/papers/DongEtAl_ICCV2019.pdf)
- An Empirical Study of CLIP for Text-based Person Search (2023). [arXiv](https://arxiv.org/html/2308.10045v2)
- Papers on diffusion/data augmentation (DA-Fusion, Effective Data Augmentation With Diffusion Models). [arXiv](https://arxiv.org/html/2302.07944v3)
- Recent empirical studies on synthetic data for TBPR (2025). [arXiv](https://arxiv.org/html/2503.22171v1)