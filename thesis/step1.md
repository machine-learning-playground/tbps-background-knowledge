# (Step 1) Backbone káº¿t há»£p

## Má»¥c tiÃªu cá»§a viá»‡c káº¿t há»£p
Káº¿t há»£p sá»©c máº¡nh alignment vÃ  optimization cá»§a TBPS-CLIP vá»›i kháº£ nÄƒng há»c chi tiáº¿t + ID calibration cá»§a VFE-TPS Ä‘á»ƒ táº¡o ra má»™t mÃ´ hÃ¬nh vá»«a cÄƒn chá»‰nh cross-modal chÃ­nh xÃ¡c, vá»«a phÃ¢n biá»‡t ngÆ°á»i tá»‘t hÆ¡n.

## ğŸ§© TÃ³m táº¯t pipeline luáº­n vÄƒn gá»£i Ã½
- Load TBPS-CLIP (ViT-B/16) checkpoint
- Freeze image & text encoder trong vÃ i epoch Ä‘áº§u (stabilize alignment).
- Add TG-MIM + IS-GVFC auxiliary branches
- Combine losses: 

![Combine losses](./img/loss.png)
- Train few-shot / zero-shot setting báº±ng meta-learning episodes.
- Evaluate trÃªn unseen IDs (zero-shot) vÃ  few-sample IDs (few-shot).

### 1) TÃ³m táº¯t ngáº¯n gá»n vá» hai aux tasks
- **TG-MIM:** che patch áº£nh, dÃ¹ng text nhÆ° key/value Ä‘á»ƒ cross-attention, rá»“i reconstruct pixel cá»§a patch bá»‹ mask (L1). Má»¥c tiÃªu: Ã©p encoder há»c **local visual cues liÃªn quan Ä‘áº¿n truy váº¥n** (mÃ  contrastive global thÆ°á»ng bá» qua).
- **IS-GVFC:** tÃ­nh phÃ¢n phá»‘i matching ná»™i bá»™ (cosine â†’ softmax) giá»¯a táº¥t cáº£ global visual features trong batch, so sÃ¡nh vá»›i phÃ¢n phá»‘i ground-truth (IDs) báº±ng KL divergence. Má»¥c tiÃªu: calibrate embedding space theo ID (kÃ©o cÃ¡c máº«u cÃ¹ng ID gáº§n láº¡i, Ä‘áº©y cÃ¡c ID khÃ¡c ra xa) mÃ  khÃ´ng cáº§n triplet mining.

### 2) VÃ¬ sao TBPS-CLIP cÃ³ thá»ƒ Ä‘Ã£ â€œláº¥pâ€ nhiá»u lá»£i Ã­ch?
TBPS-CLIP (nhÆ° bÃ i empirical) Ä‘Ã£:
- dÃ¹ng nhiá»u biáº¿n thá»ƒ contrastive (N-ITC, R-ITC, C-ITC),
- self-supervision (SS-I, SS-T),
- multi-view supervision (MVS),
- data augmentation vÃ  training tricks.

Nhá»¯ng thá»© nÃ y tá»‘i Æ°u máº¡nh cho:
- global alignment giá»¯a image/text embeddings,
- robust hÃ³a embedding chung (nhá» SS/MVS/aug),
- cáº£i thiá»‡n Rank@1 trong cáº¥u hÃ¬nh standard.

=> Há»‡ quáº£: má»™t sá»‘ lá»£i Ã­ch cÆ¡ báº£n mÃ  TG-MIM/IS-GVFC nháº¯m tá»›i (vÃ­ dá»¥, stability cá»§a embedding, robustness) cÃ³ thá»ƒ Ä‘Ã£ pháº§n nÃ o Ä‘Æ°á»£c TBPS-CLIP giáº£i quyáº¿t.

### 3) NhÆ°ng TG-MIM & IS-GVFC váº«n cÃ³ kháº£ nÄƒng bá»• sung â€” lÃ½ luáº­n chi tiáº¿t
**A. TG-MIM bá»• sung gÃ¬ mÃ  TBPS-CLIP khÃ³ thay tháº¿?**
- **Local task relevance (textâ†’patch link)**: Contrastive losses tá»‘i Æ°u similarity toÃ n cá»¥c; SS/MVS táº¡o invariance nhÆ°ng khÃ´ng Ã©p token/patch cá»¥ thá»ƒ pháº£i liÃªn quan tá»›i tá»« cá»¥ thá»ƒ trong query. TG-MIM trá»±c tiáº¿p lÃ m cho text hÆ°á»›ng dáº«n tÃ¡i táº¡o patch, tá»©c lÃ  nÃ³ dáº¡y encoder má»‘i liÃªn há»‡ cá»¥c bá»™ giá»¯a tá»« vÃ  vÃ¹ng áº£nh â€” há»¯u Ã­ch khi cÃ¡c cÃ¡ nhÃ¢n chá»‰ khÃ¡c nhau á»Ÿ chi tiáº¿t nhá» (giÃ y, balo, hoa vÄƒn).
- **Attention grounding**: TG-MIM thÆ°á»ng sáº½ khiáº¿n cross-attention trá»ng sá»‘ nháº¡y hÆ¡n vá»›i tá»« quan trá»ng â†’ cáº£i thiá»‡n interpretability vÃ  giÃºp downstream retrieval khi cÃ¢u truy váº¥n nháº¥n vÃ o chi tiáº¿t.
- **Domain adaptation nhá»**: Náº¿u CLIP pretraining dÃ¹ng áº£nh tá»± nhiÃªn, TG-MIM trÃªn dá»¯ liá»‡u pedestrian Ã©p encoder thÃ­ch nghi vá»›i phÃ¢n phá»‘i pedestrian-specific local cues.

Khi TBPS-CLIP Ä‘Ã£ cÃ³ SS/MVS, TG-MIM váº«n cÃ³ thá»ƒ cáº£i thiá»‡n hard examples (nhá»¯ng truy váº¥n cáº§n local cues). VÃ i paper bÃ¡o cÃ¡o tÄƒng nhá» nhÆ°ng á»•n Ä‘á»‹nh á»Ÿ subset â€œhardâ€.

**B. IS-GVFC bá»• sung gÃ¬?**
- **ToÃ n cá»¥c nhÆ°ng theo ID distribution**: Contrastive ITC tá»‘i Æ°u imageâ†”text match; nÃ³ khÃ´ng tá»‘i Æ°u trá»±c tiáº¿p ráº±ng cÃ¡c áº£nh cÃ¹ng ID (nhiá»u camera/times) pháº£i gáº§n nhau trong khÃ´ng gian áº£nh ná»™i táº¡i. IS-GVFC Ã©p Ä‘iá»u Ä‘Ã³ thÃ´ng qua phÃ¢n phá»‘i ná»™i áº£nh â†’ giáº£m identity confusion (khi 2 ngÆ°á»i khÃ¡c ID máº·c Ä‘á»“ giá»‘ng nhau).
- **KhÃ´ng cáº§n mining/margin**: Triplet/contrastive pair mining cÃ³ thá»ƒ khÃ³ vÃ  nháº¡y. IS-GVFC táº­n dá»¥ng toÃ n bá»™ batch distribution, á»•n Ä‘á»‹nh hÆ¡n khi batch composition Ä‘a dáº¡ng.
- **Complementary objective**: NÃ³ lÃ  objective intra-modal (visualâ†’visual) bá»• sung cho inter-modal (visualâ†”text) cá»§a TBPS-CLIP.

**C. Khi 2 aux tasks kháº£ cÃ³ Ã­ch nháº¥t**
- Datasets / queries vá»›i nhiá»u nháº§m láº«n ID (quáº§n Ã¡o giá»‘ng, Ã¡nh sÃ¡ng khÃ¡c) â†’ IS-GVFC hiá»‡u quáº£.
- Truy váº¥n chÃº trá»ng chi tiáº¿t (color, small accessories) â†’ TG-MIM hiá»‡u quáº£.
- Domain shift (suy luáº­n trÃªn dá»¯ liá»‡u khÃ¡c vá» style/camera) â†’ TG-MIM cÃ³ thá»ƒ giÃºp encoder báº¯t chi tiáº¿t domain-specific; IS-GVFC giÃºp á»•n Ä‘á»‹nh embedding.

### 4) Khi nÃ o kháº£ nÄƒng bá»• sung nhá» hoáº·c khÃ´ng Ä‘Ã¡ng ká»ƒ
- **TBPS-CLIP Ä‘Ã£ tá»‘i Æ°u triá»‡t Ä‘á»ƒ vÃ  stacking many losses**: náº¿u TBPS-CLIP Ä‘Ã£ káº¿t há»£p R-ITC + SS-I + MVS-I + paraphrase augmentation vÃ  Ä‘Ã£ fine-tune kÄ©, thÃ¬ marginal gain tá»« TG-MIM/IS-GVFC cÃ³ thá»ƒ ráº¥t nhá» (<<1% Rank@1).
- **Náº¿u test set Ä‘Æ¡n giáº£n, khÃ´ng nhiá»u hard cases**, báº¡n sáº½ khÃ³ tháº¥y lá»£i Ã­ch.
- **Chi phÃ­ training tÄƒng**: TG-MIM vÃ  IS-GVFC Ä‘á»u tÄƒng overhead (TG-MIM: reconstruct decoder/conv head; IS-GVFC: compute full similarity matrix). Náº¿u tÃ i nguyÃªn háº¡n cháº¿, overhead cÃ³ thá»ƒ khÃ´ng xá»©ng Ä‘Ã¡ng.

### 5) Káº¾ HOáº CH THÃ NGHIá»†M (Ä‘á»ƒ Ä‘o chÃ­nh xÃ¡c hiá»‡u quáº£) â€” báº¯t buá»™c cho luáº­n vÄƒn

Thiáº¿t káº¿ thÃ­ nghiá»‡m pháº£i tráº£ lá»i: TG-MIM vÃ  IS-GVFC cÃ³ mang láº¡i cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ so vá»›i TBPS-CLIP Ä‘Ã£ tá»‘i Æ°u khÃ´ng?

**A. Baselines**
- TBPS-CLIP (strong reimplementation) â€” reprod. best single-loss/stack combo (R-ITC + SS-I + MVS-I + augmentations) â€” gá»i lÃ  Base.
- Base + TG-MIM
- Base + IS-GVFC
- Base + TG-MIM + IS-GVFC (full)
- (optional) VFE-TPS original and RaSa for comparison

**B. Datasets & splits**
- CUHK-PEDES (standard), RSTPReid (if available).
- Create "hard subset": queries where correct match is visually similar to distractors (same clothing color etc.). Evaluate separately.
- Open-set test (unseen domain / unseen ID split): test generalization.

**C. Metrics**
- Rank@1, Rank@5, mAP.
- Hard-case gain: Î”Rank@1 on hard subset.
- Statistical test: run 3 seeds, report mean Â± std, do paired t-test to verify significance (p<0.05).

**D. Computational cost reporting**
- Training time per epoch, total epochs to converge, GPU memory, inference latency.
- Compute efficiency vs gain tradeoff (e.g., %Rank1 gain per 10% more training time).

**E. Qualitative analysis**
- Visualize cross-attention maps for TG-MIM vs Base.
- Nearest neighbor in visual embedding space before/after IS-GVFC to see clustering.
- Failure case study.

**F. Hyperparameters to tune**
- Loss weights Î»_TG, Î»_IS; temperature Ï„ for softmax; mask ratio for TG-MIM; batch size (IS-GVFC sensitive).
- Schedule: ramp up aux losses after warming up Base training (e.g., first 5â€“10 epochs freeze CLIP then enable TG-MIM).

### 6) Practical recommendations (implementation & training strategy)
- Start from TBPS-CLIP checkpoint (fast, less risky).
- Phase training:
    - Phase 1 (warm-up): train only contrastive (R-ITC/C-ITC) + SS/MVS as in TBPS-CLIP for stability (5â€“10 epochs).
    - Phase 2: enable IS-GVFC with small weight Î»_IS = 0.05 â†’ 0.2 (tune). Batch size large (B â‰¥ 64) to have many pairwise comparisons. Temperature Ï„ same as ITC (0.07â€“0.2).
    - Phase 3: enable TG-MIM with Î»_TG = 0.1 (tiny to start). Mask ratio = 0.3â€“0.5; reconstruction head light (Conv2D+PixelShuffle). Use L1 loss. After stable, possibly unfreeze few encoder layers.
    - Phase 4: final joint fine-tune, tune Î»s by grid search (Î»_IS âˆˆ {0.05,0.1,0.2}; Î»_TG âˆˆ {0.05,0.1,0.2}).
- Batch size: IS-GVFC benefits from larger batch (better estimation of distribution) â€” try to maximize batch size within memory.
- Compute budget: measure tradeoff; if TG-MIM adds >>20â€“30% train time but only +0.2% Rank@1, consider removing.
- Hyperparam gá»£i Ã½
    - temperature Ï„ (contrastive) = 0.07 (CLIP default) â†’ tune 0.05â€“0.2
    - batch size = as large as memory allows (â‰¥64 recommended for IS-GVFC)
    - mask ratio (TG-MIM) = 30â€“50%
    - TG-MIM reconstruction loss = L1; learning rate for decoder head 1e-4, for encoders 1e-5 (if fine-tuning)
    - IS-GVFC uses KL between p and q; q is normalized per anchor over same-ID entries.

### 7) Expected effect sizes (practical guidance) [ablation]
- If TBPS-CLIP Base is well-tuned, typical realistic gains:
    - Base + IS-GVFC: +0.3% â€¦ +1.5% Rank@1 on general set; larger (+1â€“3%) on hard subset.
    - Base + TG-MIM: +0.2% â€¦ +1.5% Rank@1 overall; larger on queries needing local cues.
    - Both combined: effects may be additive for hard cases; overall Î”Rank@1 maybe ~0.5â€“3% depending on dataset difficulty.
- If Base is weaker (no SS/MVS), gains can be larger.

Nhá»¯ng con sá»‘ trÃªn lÃ  Æ°á»›c lÆ°á»£ng dá»±a trÃªn lÃ½ luáº­n vÃ  kinh nghiá»‡m trong literature (not exact). Äá»™ tin cáº­y phá»¥ thuá»™c vÃ o dataset vÃ  reimplementation quality.

### 8) CÃ¡c rá»§i ro & mitigations
- Rá»§i ro: Overfitting aux tasks (TG-MIM reconstructs uninformative pixels) â†’ giáº£m cross-modal alignment.
- Mitigate: use small Î»_TG, early stopping on retrieval metric, mask ratio tuning.

- Rá»§i ro: IS-GVFC bá»‹ batch-biased (batch composition áº£nh hÆ°á»Ÿng phÃ¢n phá»‘i).
- Mitigate: ensure batch sampling includes multiple IDs, shuffle; test sensitivity to batch size.

- Rá»§i ro: Training time blowup.
- Mitigate: phase enabling, lightweight decoder head, mixed precision.

### 9) Káº¿t luáº­n & khuyáº¿n nghá»‹ tÃ³m táº¯t
- LÃ½ luáº­n: TG-MIM vÃ  IS-GVFC cÃ³ thá»ƒ mang láº¡i giÃ¡ trá»‹ bá»• sung Ä‘á»‘i vá»›i má»™t TBPS model Ä‘Ã£ máº¡nh nhÆ° TBPS-CLIP, nhÆ°ng lá»£i Ã­ch thá»±c táº¿ phá»¥ thuá»™c máº¡nh vÃ o:
    - cháº¥t lÆ°á»£ng baseline (Base Ä‘Ã£ Ä‘Æ°á»£c tuned tháº¿ nÃ o),
    - tá»· lá»‡ hard cases trong dataset,
    - tÃ i nguyÃªn tÃ­nh toÃ¡n vÃ  cÃ¡ch tÃ­ch há»£p (loss weighting, schedule).
- Chiáº¿n lÆ°á»£c thá»±c nghiá»‡m tá»‘i Æ°u cho luáº­n vÄƒn: báº¯t Ä‘áº§u tá»« TBPS-CLIP checkpoint, lÃ m controlled ablations (Base â†’ +IS â†’ +TG â†’ +Both), report gains overall + on hard subset + cost metrics, vÃ  kÃ¨m visualization.
- Náº¿u báº¡n cáº§n recommendation duy nháº¥t: lÃ m theo pipeline fine-tune (khÃ´ng train tá»« Ä‘áº§u), tune weights nhá», bÃ¡o cÃ¡o tradeoff; chá»‰ tiáº¿n tá»›i training from scratch náº¿u báº¡n cÃ³ thá»i gian/GPU dÆ° dáº£.