# (Step 2) Zero-shot / few-shot
Náº¿u chá»‰ dá»«ng láº¡i á»Ÿ viá»‡c **káº¿t há»£p TBPS-CLIP vÃ  VFE-TPS**, thÃ¬ Ä‘Ã³ **chÆ°a Ä‘á»§ â€œunique contributionâ€** cho luáº­n vÄƒn tháº¡c sÄ©, vÃ¬ nÃ³ váº«n náº±m trong pháº¡m vi â€œengineering fusionâ€ (láº¥y loss A + loss B).

â†’ Äá»ƒ nÃ¢ng cáº¥p thÃ nh **má»™t Ä‘á» tÃ i cÃ³ tÃ­nh nghiÃªn cá»©u thá»±c nghiá»‡m vÃ  Ä‘Ã³ng gÃ³p riÃªng**, báº¡n cáº§n **lÃ m rÃµ cÆ¡ cháº¿ zero/few-shot adaptation, cÃ¡ch táº­n dá»¥ng prompting / augmentation / lightweight adaptation**, chá»© khÃ´ng chá»‰ mix loss.

## ğŸ¯ Má»¥c tiÃªu: lÃ m rÃµ yáº¿u tá»‘ unique contribution vá» Zero/Few-Shot Generalization
DÆ°á»›i Ä‘Ã¢y lÃ  3 hÆ°á»›ng mÃ  báº¡n cÃ³ thá»ƒ **chá»©ng minh rÃµ rÃ ng tÃ­nh má»›i** â€” Ä‘á»u dá»±a trÃªn ná»n TBPS-CLIP + VFE-TPS nhÆ°ng má»Ÿ rá»™ng Ä‘Ãºng hÆ°á»›ng â€œEmpirical Zero/Few-Shotâ€.

### ğŸ”¹ (1) Zero/Few-Shot thÃ´ng qua Prompt-Guided Adaptation (unique Ä‘iá»ƒm 1)
- **Ã tÆ°á»Ÿng cá»‘t lÃµi:** CLIP backbone Ä‘Ã£ cÃ³ kháº£ nÄƒng zero-shot (tá»« pretrain). Thay vÃ¬ fine-tune toÃ n bá»™, báº¡n chá»‰ **thÃªm má»™t module â€œprompt adapterâ€** (learnable textual/visual prompt) Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ Ä‘iá»u chá»‰nh khÃ´ng gian embedding phÃ¹ há»£p vá»›i task TBPS.
- **Cá»¥ thá»ƒ:**
    - **Text side:** thÃªm learnable textual prompts [Pâ‚, Pâ‚‚, â€¦, Pâ‚–] ná»‘i trÆ°á»›c/sau caption, vÃ­ dá»¥ "person with" [Pâ‚] "red jacket" [Pâ‚‚] "in the street".
    Chá»‰ update [P], freeze CLIP encoder â†’ giáº£m chi phÃ­ train/inference.
    - **Visual side:** thÃªm Visual Prompt Tuning (VPT): má»™t sá»‘ learnable tokens chÃ¨n vÃ o ViT input (giá»‘ng Prefix-tuning).
    - **CÃ¡ch há»c:** supervision qua contrastive (ITC/R-ITC) + TG-MIM (Ä‘á»ƒ giá»¯ grounding).
    => Cho phÃ©p **quick adaptation** sang unseen ID descriptions (zero-shot) hoáº·c vá»›i vÃ i sample (few-shot).
- **GiÃ¡ trá»‹:**
    - **Giáº£m training cost** (freeze backbone).
    - **Zero/Few-shot capability:** vÃ¬ backbone váº«n giá»¯ knowledge tá»« pretrain CLIP, prompt há»c ngá»¯ cáº£nh má»›i nhanh.
    - ÄÃ¢y lÃ  Ä‘iá»ƒm â€œuniqueâ€ dá»… mÃ´ táº£, cÃ³ thá»ƒ chá»©ng minh báº±ng ablation.

### ğŸ”¹ (2) Data Augmentation hÆ°á»›ng ngá»¯ nghÄ©a (unique Ä‘iá»ƒm 2)
**KhÃ´ng chá»‰ paraphrase text**, mÃ  báº¡n cho phÃ©p **semantic interpolation** giá»¯a captions cá»§a cÃ¹ng ID.
- **VÃ­ dá»¥:**
    - 2 mÃ´ táº£ cá»§a cÃ¹ng ID:
    - Tâ‚ = â€œman wearing red jacketâ€,
    - Tâ‚‚ = â€œmale with a crimson coatâ€
    - â†’ sinh vector trung gian T_mix = Î±Â·E(Tâ‚) + (1âˆ’Î±)Â·E(Tâ‚‚)
    - â†’ xem nhÆ° 1 caption â€œlatent paraphraseâ€ Ä‘á»ƒ augment training contrastive pairs.
- **GiÃ¡ trá»‹:**
    - Táº¡o â€œsemantic continuumâ€ trong text space â†’ model há»c khÃ¡i niá»‡m thay vÃ¬ caption cá»¥ thá»ƒ.
    - GiÃºp zero-shot generalization vÃ¬ model khÃ´ng phá»¥ thuá»™c vÃ o phrasing cá»¥ thá»ƒ.
- **Triá»ƒn khai:**
    - Ráº¥t nháº¹ (khÃ´ng cáº§n LLM sinh thÃªm caption).
    - CÃ³ thá»ƒ káº¿t há»£p vá»›i CLIP tokenizer (cosine blending trong embedding space).

### ğŸ”¹ (3) Meta-Learning Episodic Training (unique Ä‘iá»ƒm 3)
**MÃ´ phá»ng zero/few-shot scenario trong training.**
- Cá»¥ thá»ƒ:
    - Chia táº­p train thÃ nh cÃ¡c episodic tasks: má»—i episode chá»‰ gá»“m má»™t sá»‘ ID (support set + query set).
    - Trong má»—i episode: model há»c alignment textâ†”image cá»§a nhá»¯ng ID â€œnhá»â€, rá»“i cáº­p nháº­t qua meta-gradient (MAML-like hoáº·c ProtoNet-style).
    - Khi test trÃªn unseen ID, mÃ´ hÃ¬nh Ä‘Ã£ há»c cÃ¡ch â€œthÃ­ch nghi nhanhâ€ chá»‰ tá»« vÃ i vÃ­ dá»¥ (few-shot).
- GiÃ¡ trá»‹:
    - ÄÆ°a ra cÃ¡ch huáº¥n luyá»‡n mÃ´ phá»ng Ä‘Ãºng zero/few-shot setting, thay vÃ¬ chá»‰ nÃ³i â€œtest unseenâ€.
    - CÃ³ thá»ƒ dÃ¹ng framework nhÆ° Higher (PyTorch) Ä‘á»ƒ cÃ i Ä‘áº·t nhanh.

## ğŸ’¡ TÃ³m táº¯t cÃ¡ch káº¿t há»£p (Ä‘á»ƒ cÃ³ Ä‘Ã³ng gÃ³p Ä‘á»™c láº­p tháº­t sá»±)
| ThÃ nh pháº§n                                 | Tá»« Ä‘Ã¢u                               | Vai trÃ² chÃ­nh                            | ÄÃ³ng gÃ³p má»›i                           |
|--------------------------------------------|--------------------------------------|------------------------------------------|----------------------------------------|
| **TBPS-CLIP**                              | Baseline máº¡nh (contrastive, SS, MVS) | Global alignment, backbone               | Ná»n Ä‘á»ƒ freeze cho adaptation           |
| **TG-MIM (VFE-TPS)**                       | VFE-TPS                              | Local text-guided reconstruction         | Giá»¯ grounding khi prompt tuning        |
| **IS-GVFC (VFE-TPS)**                      | VFE-TPS                              | Intra-visual calibration                 | Giá»¯ cluster ID á»•n Ä‘á»‹nh trong few-shot  |
| ğŸ”¸ **Prompt-Guided Adaptation**            | (Ä‘á» xuáº¥t má»›i)                        | Lightweight fine-tune cho zero/few-shot  | âœ… Unique                             |
| ğŸ”¸ **Semantic Interpolation Augmentation** | (Ä‘á» xuáº¥t má»›i)                        | LÃ m má»‹n khÃ´ng gian ngá»¯ nghÄ©a             | âœ… Unique                             |
| ğŸ”¸ **Meta-Learning Episodic Training**     | (Ä‘á» xuáº¥t má»›i)                        | Huáº¥n luyá»‡n mÃ´ phá»ng zero/few-shot        | âœ… Unique                             |

## ğŸ”¬ Báº¡n cÃ³ thá»ƒ mÃ´ táº£ khung thá»±c nghiá»‡m nhÆ° sau:
- Giai Ä‘oáº¡n 1: pretrain base model (TBPS-CLIP + IS-GVFC + TG-MIM).
- Giai Ä‘oáº¡n 2: freeze backbone, train Prompt Adapter + semantic augmentation.
- Giai Ä‘oáº¡n 3: episodic fine-tune (meta-learning) cho few-shot adaptation.
- Giai Ä‘oáº¡n 4: evaluate zero-shot (unseen IDs) vÃ  few-shot (k=1, 5, 10) trÃªn CUHK-PEDES / RSTPReid.

## ğŸ” Gá»£i Ã½ tÃªn cho Ä‘Ã³ng gÃ³p chÃ­nh:
**Prompt-Adaptive Cross-Modal Alignment for Zero/Few-Shot Text-based Person Search (PACA-TPS)**

hoáº·c ngáº¯n hÆ¡n: **Prompt-Enhanced TBPS**